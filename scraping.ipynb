{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b74bf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lxml\n",
    "from sys import getsizeof\n",
    "from time import strptime, strftime\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import Timeout, ConnectionError, HTTPError, RequestException\n",
    "from tqdm.notebook import tqdm\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed80c8",
   "metadata": {},
   "source": [
    "# RSS Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "826b07c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<entry>\n",
      "<title>10-Q - Legacy Housing Corp (0001436208) (Filer)</title>\n",
      "<link href=\"https://www.sec.gov/Archives/edgar/data/1436208/000155837022014338/0001558370-22-014338-index.htm\" rel=\"alternate\" type=\"text/html\"/>\n",
      "<summary type=\"html\">\n",
      " &lt;b&gt;Filed:&lt;/b&gt; 2022-09-12 &lt;b&gt;AccNo:&lt;/b&gt; 0001558370-22-014338 &lt;b&gt;Size:&lt;/b&gt; 7 MB\n",
      "</summary>\n",
      "<updated>2022-09-12T17:30:09-04:00</updated>\n",
      "<category label=\"form type\" scheme=\"https://www.sec.gov/\" term=\"10-Q\"/>\n",
      "<id>urn:tag:sec.gov,2008:accession-number=0001558370-22-014338</id>\n",
      "</entry>\n"
     ]
    }
   ],
   "source": [
    "def rss_url(start=0, count=100):\n",
    "    type = '10-'\n",
    "    return f'https://www.sec.gov/cgi-bin/browse-edgar?action=getcurrent&CIK=&type={type}&company=&dateb=&owner=include&start={start}&count={count}&output=atom'\n",
    "\n",
    "def check_validity(entry: BeautifulSoup) -> str:\n",
    "    acc_pattern = re.compile(r'(\\d{10}\\-\\d{2}\\-\\d{6})')\n",
    "    acc_1 = acc_pattern.search(entry.find('summary').text).group()\n",
    "    acc_2 = acc_pattern.search(entry.find('id').text).group()\n",
    "    if acc_1 == acc_2:\n",
    "        return acc_1\n",
    "    raise ValueError(f'Invalid accession number: {acc_1} != {acc_2}')\n",
    "    # Not sure if this is necessary\n",
    "    return None\n",
    "\n",
    "def get_filing_date(entry: BeautifulSoup) -> str:\n",
    "    summary = entry.find('summary').text\n",
    "    date_pattern = re.compile(r'(\\d{4}\\-\\d+\\-\\d+)')\n",
    "    date = date_pattern.search(summary).group()\n",
    "    return date\n",
    "\n",
    "def get_url(entry: BeautifulSoup) -> list:\n",
    "    url = entry.find('link')['href']\n",
    "    url.replace('-index.htm', '.txt')\n",
    "    return url\n",
    "\n",
    "def get_header(document: BeautifulSoup) -> dict:\n",
    "    \"\"\"Return the header of the txt file.\"\"\"\n",
    "    def find_acc(txt: str) -> str:\n",
    "        return txt[txt.find('ACCESSION NUMBER:') + 17:txt.find('CONFORMED SUBMISSION TYPE:')].strip()\n",
    "    def find_cik(txt: str) -> str:\n",
    "        return txt[txt.find('CENTRAL INDEX KEY:') + 18:txt.find('STANDARD INDUSTRIAL CLASSIFICATION:')].strip()\n",
    "    def find_irs(txt: str) -> str:\n",
    "        return txt[txt.find('IRS NUMBER:') + 11:txt.find('STATE OF INCORPORATION:')].strip()\n",
    "    def find_form(txt: str) -> str:\n",
    "        return txt[txt.find('CONFORMED SUBMISSION TYPE:') + 26:txt.find('PUBLIC DOCUMENT COUNT:')].strip()\n",
    "    def find_name(txt: str) -> str:\n",
    "        return txt[txt.find('COMPANY CONFORMED NAME:') + 23:txt.find('CENTRAL INDEX KEY:')].strip()\n",
    "    def find_date(txt: str) -> str:\n",
    "        return txt[txt.find('FILED AS OF DATE:') + 17:txt.find('DATE AS OF CHANGE:')].strip()\n",
    "    def identify_markup(document: BeautifulSoup) -> str:\n",
    "        markup_list = ['html', 'xml', 'xbrl']\n",
    "        next = document.find('TEXT').next\n",
    "        markup = next.name if next.name else next.next.name\n",
    "        markup = markup.lower()\n",
    "        if markup not in markup_list:\n",
    "            raise ValueError(f'Invalid markup: {markup}')\n",
    "        return markup\n",
    "            \n",
    "    txt = document.text\n",
    "    header = txt[txt.find('<SEC-HEADER>') + 12:txt.find('</SEC-HEADER>')]\n",
    "    header_dict = {\n",
    "        'acc': find_acc(header),\n",
    "        'cik': find_cik(header),\n",
    "        'irs': find_irs(header),\n",
    "        'form': find_form(header),\n",
    "        'coname': find_name(header),\n",
    "        'date': find_date(header),\n",
    "        'markup': identify_markup(document)\n",
    "    }\n",
    "    return header_dict\n",
    "\n",
    "def soup_to_df(soup: BeautifulSoup) -> pd.DataFrame:\n",
    "    header = soup.find('SEC-HEADER')\n",
    "    header = get_header(header)\n",
    "    document = soup.find('DOCUMENT')\n",
    "    document = {'text': document.text}\n",
    "    df = pd.DataFrame([{**header, **document}])\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    HEADERS = {\n",
    "        'Content-Type': 'application/json; charset=utf-8', \n",
    "        'User-Agent': 'cdo@oneline.tec',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Host': 'www.sec.gov'\n",
    "    }\n",
    "    # get last server access time from s3://oneline-access-log/edgar/edgar.log\n",
    "    # 상단 링크 변경 필요\n",
    "    LAST_DATE = strptime('2020-01-01', '%Y-%m-%d')\n",
    "    \n",
    "    num = 0\n",
    "    while count == 0:\n",
    "        count = 0\n",
    "        df = pd.DataFrame()\n",
    "        req = requests.get(rss_url(start=num*100, count=100), headers=HEADERS)\n",
    "        soup = BeautifulSoup(req.text, 'xml')\n",
    "\n",
    "        entries = soup.find_all('entry')\n",
    "        link_list = ((get_url(i), get_filing_date(i)) for i in entries)\n",
    "        for url, date in link_list:\n",
    "            if strptime(date, '%Y-%m-%d') < LAST_DATE:\n",
    "                count += 1\n",
    "                continue\n",
    "            requ = requests.get(url, headers=HEADERS)\n",
    "            document = BeautifulSoup(requ.text, 'xml')\n",
    "            df = pd.concat([df, soup_to_df(document)])\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b700649",
   "metadata": {},
   "outputs": [],
   "source": [
    "### request header 차단당했을 때 이용\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\")\n",
    "options.add_argument(\"lang=ko_KR\")\n",
    "driver = webdriver.Chrome('chromedriver', options=options)\n",
    "\n",
    "driver.get(rss_url)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80171b5",
   "metadata": {},
   "source": [
    "## 전처리 이후 s3 업로드, bigquery 로드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(r'whatasamplepath/path')\n",
    "date = strftime('%Y%m%d', LAST_DATE)\n",
    "name = f'edgar_scrap_{date}.parquet'\n",
    "df.to_parquet(path / name, index=False)\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "from sys import getsizeof\n",
    "\n",
    "ARN = 'arn:aws:s3:::oneline-edgar'\n",
    "S3_BUCKET = 'oneline-edgar'\n",
    "KEY_LIST = \"'0123','6789'\"\n",
    "S3_FILE = '1994_0.parquet'\n",
    "REGION = 'ap-northeast-2'   # Seoul\n",
    "AWSAccessKeyId, AWSSecretKey = open('awskey.txt').read().splitlines()\n",
    "\n",
    "s3:boto3.Session = boto3.client('s3', region_name=REGION, aws_access_key_id=AWSAccessKeyId, aws_secret_access_key=AWSSecretKey)\n",
    "s3.upload_file(path / name, S3_BUCKET, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5e2bb",
   "metadata": {},
   "source": [
    "# 하단 코드 개수 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7688e30",
   "metadata": {},
   "source": [
    "# Company reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15466f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filings_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0, len(cik_df))):\n",
    "    cik = cik_df['cik'][i]\n",
    "    url = f'http://data.sec.gov/submissions/CIK{cik}.json'\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            edgar = requests.get(url, headers = HEADERS)\n",
    "\n",
    "            if edgar.status_code != 200:\n",
    "                print(\"Not 200\")\n",
    "                continue\n",
    "            else:\n",
    "                edgar = edgar.json()    \n",
    "\n",
    "            name = edgar['name'] ; ticker = \";\".join(edgar['tickers']) ; exchange = \";\".join(edgar['exchanges'])\n",
    "            \n",
    "            filings = pd.DataFrame(edgar['filings']['recent'])\n",
    "            filings = filings[(filings['form']=='10-Q') | (filings['form']=='10-K')]\n",
    "            \n",
    "            filings['cik'] = cik ; filings['name'] = name\n",
    "            filings['ticker'] = ticker ; filings['exchange'] = exchange\n",
    "            \n",
    "            filings_df = pd.concat([filings_df, filings]).reset_index(drop = True)\n",
    "\n",
    "            break\n",
    "            \n",
    "        except (Timeout, ConnectionError, HTTPError, RequestException):\n",
    "            print(\"Error\")\n",
    "            continue\n",
    "\n",
    "# cik_list.extend(cik)\n",
    "# accessionNumber_list.extend(accessionNumber)\n",
    "# form_list.extend(form)\n",
    "# primaryDocument_list.extend(primaryDocument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df = filings_df[['cik', 'name', 'ticker', 'exchange', 'accessionNumber', 'filingDate',\n",
    "                         'reportDate', 'acceptanceDateTime', 'act', 'form', 'fileNumber', 'filmNumber', # delete items\n",
    "                         'size', 'isXBRL', 'isInlineXBRL', 'primaryDocument', 'primaryDocDescription']] #reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f828e073",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aaca51",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df.to_csv(\"filings_df.csv\", encoding = \"utf-8\", index  = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d0dde8",
   "metadata": {},
   "source": [
    "# Reports Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e11dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df = pd.read_csv(\"filings_df.csv\", encoding = \"utf-8\")\n",
    "\n",
    "# primaryDocument 없는 경우도 있음.\n",
    "filings_df = filings_df.dropna(subset=['primaryDocument']).reset_index(drop = True)\n",
    "\n",
    "filings_df['cik'] = filings_df['cik'].apply(lambda x: str(x).zfill(10))\n",
    "filings_df['act'] = filings_df['act'].fillna(-1)\n",
    "filings_df['act'] = filings_df['act'].apply(lambda x: int(x))\n",
    "\n",
    "filings_df['filmNumber'] = filings_df['filmNumber'].fillna(-1)\n",
    "filings_df['filmNumber'] = filings_df['filmNumber'].apply(lambda x: str(x).replace(\",\",\"\"))\n",
    "filings_df['filmNumber'] = filings_df['filmNumber'].apply(lambda x: int(float(x))) # ['filmNumber']==17010285.17010284]\n",
    "# filings_df['filmNumber'] = filings_df['filmNumber'].apply(lambda x: re.sub(r\"[0-9]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c811886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>accessionNumber</th>\n",
       "      <th>filingDate</th>\n",
       "      <th>reportDate</th>\n",
       "      <th>acceptanceDateTime</th>\n",
       "      <th>act</th>\n",
       "      <th>form</th>\n",
       "      <th>fileNumber</th>\n",
       "      <th>filmNumber</th>\n",
       "      <th>size</th>\n",
       "      <th>isXBRL</th>\n",
       "      <th>isInlineXBRL</th>\n",
       "      <th>primaryDocument</th>\n",
       "      <th>primaryDocDescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Nasdaq</td>\n",
       "      <td>0000320193-22-000059</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>2022-03-26</td>\n",
       "      <td>2022-04-28T18:03:58.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>001-36743</td>\n",
       "      <td>22868650</td>\n",
       "      <td>6140838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aapl-20220326.htm</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Nasdaq</td>\n",
       "      <td>0000320193-22-000007</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>2022-01-27T18:00:58.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>001-36743</td>\n",
       "      <td>22564628</td>\n",
       "      <td>5669748</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aapl-20211225.htm</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Nasdaq</td>\n",
       "      <td>0000320193-21-000105</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>2021-09-25</td>\n",
       "      <td>2021-10-28T18:04:28.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>10-K</td>\n",
       "      <td>001-36743</td>\n",
       "      <td>211359752</td>\n",
       "      <td>10502096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aapl-20210925.htm</td>\n",
       "      <td>10-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Nasdaq</td>\n",
       "      <td>0000320193-21-000065</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>2021-07-27T18:03:42.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>001-36743</td>\n",
       "      <td>211119137</td>\n",
       "      <td>8446381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aapl-20210626.htm</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000320193</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Nasdaq</td>\n",
       "      <td>0000320193-21-000056</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>2021-03-27</td>\n",
       "      <td>2021-04-28T18:02:54.000Z</td>\n",
       "      <td>34</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>001-36743</td>\n",
       "      <td>21866148</td>\n",
       "      <td>8468959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aapl-20210327.htm</td>\n",
       "      <td>10-Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik        name ticker exchange       accessionNumber  filingDate  \\\n",
       "0  0000320193  Apple Inc.   AAPL   Nasdaq  0000320193-22-000059  2022-04-29   \n",
       "1  0000320193  Apple Inc.   AAPL   Nasdaq  0000320193-22-000007  2022-01-28   \n",
       "2  0000320193  Apple Inc.   AAPL   Nasdaq  0000320193-21-000105  2021-10-29   \n",
       "3  0000320193  Apple Inc.   AAPL   Nasdaq  0000320193-21-000065  2021-07-28   \n",
       "4  0000320193  Apple Inc.   AAPL   Nasdaq  0000320193-21-000056  2021-04-29   \n",
       "\n",
       "   reportDate        acceptanceDateTime  act  form fileNumber  filmNumber  \\\n",
       "0  2022-03-26  2022-04-28T18:03:58.000Z   34  10-Q  001-36743    22868650   \n",
       "1  2021-12-25  2022-01-27T18:00:58.000Z   34  10-Q  001-36743    22564628   \n",
       "2  2021-09-25  2021-10-28T18:04:28.000Z   34  10-K  001-36743   211359752   \n",
       "3  2021-06-26  2021-07-27T18:03:42.000Z   34  10-Q  001-36743   211119137   \n",
       "4  2021-03-27  2021-04-28T18:02:54.000Z   34  10-Q  001-36743    21866148   \n",
       "\n",
       "       size  isXBRL  isInlineXBRL    primaryDocument primaryDocDescription  \n",
       "0   6140838       1             1  aapl-20220326.htm                  10-Q  \n",
       "1   5669748       1             1  aapl-20211225.htm                  10-Q  \n",
       "2  10502096       1             1  aapl-20210925.htm                  10-K  \n",
       "3   8446381       1             1  aapl-20210626.htm                  10-Q  \n",
       "4   8468959       1             1  aapl-20210327.htm                  10-Q  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filings_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ae244",
   "metadata": {},
   "source": [
    "### API 우선 100개의 cik에 대해서 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a54ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cik_list = list(filings_df['cik'].drop_duplicates())\n",
    "temp_df = filings_df[['cik']].drop_duplicates().reset_index(drop = True)\n",
    "temp_df = list(temp_df.sample(100, random_state= 7)['cik'])\n",
    "\n",
    "filings_df = filings_df[filings_df['cik'].isin(temp_df)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97052e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_list = list(filings_df['cik'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eabc9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-agent\":'cmo@onelinetec.com'}\n",
    "\n",
    "\n",
    "key_path = glob.glob('*.json')[0]\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "project_id = 'fine-scene-356009'\n",
    "table_id = 'cik_filings.cik_contents'\n",
    "client = bigquery.Client(credentials = credentials, project = credentials.project_id)                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "026251b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 90.6 ms, sys: 18.5 ms, total: 109 ms\n",
      "Wall time: 886 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QueryJob<project=fine-scene-356009, location=asia-northeast3, id=6c91ecd3-039b-4bd8-b74c-4fb2dc1bd1a7>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sql = f\"\"\"\n",
    "DELETE FROM `{project_id}.{table_id}` WHERE true;\n",
    "\"\"\"\n",
    "\n",
    "client.query(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_elements = [f'.//table', f'//*[@id=\"DSPFPageNumber\"]', \"//div[@style='text-align:center']\", f'.//head', \"//div[@style='display:none']\"]\n",
    "stop_words = ['☐','☒']\n",
    "\n",
    "# This function will be our all-in-one noise removal function\n",
    "def remove_stopwords(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            cleaned_tokens.append(token.strip())\n",
    "    cleaned_tokens = list(filter(None, cleaned_tokens))\n",
    "    return cleaned_tokens\n",
    "\n",
    "\n",
    "for index in tqdm(range(0, len(cik_list))):\n",
    "    cik = cik_list[index]\n",
    "    temp_df = filings_df[filings_df['cik']==cik].reset_index(drop = True)\n",
    "    name = temp_df['name'][0]\n",
    "    content_list = [] # init\n",
    "    \n",
    "    for k in range(0, len(temp_df)):\n",
    "        \n",
    "        accessionNumber = temp_df['accessionNumber'][k].replace(\"-\",\"\")\n",
    "        primaryDocument = temp_df['primaryDocument'][k]    \n",
    "\n",
    "        url = f'https://www.sec.gov/Archives/edgar/data/{cik}/{accessionNumber}/{primaryDocument}'\n",
    "        response = requests.get(url, headers = headers)\n",
    "        response = BeautifulSoup(response.content, \"html.parser\")\n",
    "        try:\n",
    "            response = etree.HTML(str(response))\n",
    "        except ValueError: # Unicode strings with encoding declaration are not supported\n",
    "            response = etree.HTML(bytes(str(response), encoding='utf-8'))\n",
    "\n",
    "        for p in del_elements:\n",
    "            if p == f'.//table':\n",
    "                for i in response.xpath(p):\n",
    "                    if len(i) != 1:  # 테이블로 형태의 텍스트를 제외하고는 삭제\n",
    "                        i.getparent().remove(i)\n",
    "            else:        \n",
    "                for i in response.xpath(p): #pagination 일반화가능?\n",
    "                    i.getparent().remove(i)  \n",
    "\n",
    "        content = response.xpath(f'.//text()')\n",
    "        content = remove_stopwords(content)\n",
    "        content = \" \".join(content)\n",
    "        content = re.sub(r\"\\s+\", \" \", content)\n",
    "        content_list.append(content)\n",
    "        \n",
    "    temp_df['content'] = content_list\n",
    "    temp_df.to_gbq(table_id, project_id, if_exists='append', credentials = credentials)\n",
    "    print(f\"{cik}-{name} completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('general')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f5d32f057a3c8bd6a68a4140140c1c01731d179f143636ed2ae590c641a050cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
